# File: scripts/infer.py (V8.8: End-to-End Pure Poem Inference)

import sys
import os
import argparse
import torch
import numpy as np
import yaml
from PIL import Image
from transformers import BertTokenizer
from pathlib import Path
from diffusers import StableDiffusionControlNetPipeline, ControlNetModel

# === è·¯å¾„é…ç½® & å¯¼å…¥ ===
current_file_path = os.path.abspath(__file__)
# å‡è®¾è„šæœ¬åœ¨ scripts/ æˆ– stage2_generation/ ç›®å½•ä¸‹ï¼Œå‘ä¸Šæ‰¾ä¸¤çº§åˆ°é¡¹ç›®æ ¹ç›®å½•
project_root = os.path.dirname(os.path.dirname(current_file_path))
if project_root not in sys.path:
    sys.path.insert(0, project_root)

# å¯¼å…¥é¡¹ç›®ç»„ä»¶
try:
    from models.poem2layout import Poem2LayoutGenerator
    from inference.greedy_decode import greedy_decode_poem_layout
    # ç¡®ä¿ ink_mask æ˜¯ V8.6+ æ”¯æŒçº¹ç†çš„ç‰ˆæœ¬
    from stage2_generation.utils.ink_mask import InkWashMaskGenerator
    from data.visualize import draw_layout
except ImportError as e:
    print(f"[Error] æ¨¡å—å¯¼å…¥å¤±è´¥: {e}")
    print(f"å½“å‰ sys.path: {sys.path}")
    sys.exit(1)

# =============================================================
# [V8.0 ç»„ä»¶] æ€åŠ¿æ„ŸçŸ¥æ³¨æ„åŠ›å¤„ç†å™¨ (PoemInkAttentionProcessor)
# =============================================================
class PoemInkAttentionProcessor:
    """
    V8.0 æ ¸å¿ƒï¼šå°† 8 ç»´å¸ƒå±€ä¸­çš„ç‰©ç†æ€åŠ¿ (Bias) æ³¨å…¥åˆ° Cross-Attention ä¸­ã€‚
    ç¡®ä¿ç”Ÿæˆçš„ç”»é¢ç¬”è§¦ä¸ InkMask çš„åŠ¨æ€å¢¨è¿¹ä½ç½®ä¸€è‡´ã€‚
    """
    def __init__(self, dynamic_layout, tokenizer, prompt, device, scale=8.0):
        # dynamic_layout: [N, 9] -> (cls, cx, cy, w, h, bx, by, rot, flow)
        self.layout = dynamic_layout  
        self.tokenizer = tokenizer
        self.prompt = prompt
        self.device = device
        self.scale = scale 

        self.class_to_keyword = {
            2: "å±±", 3: "æ°´", 4: "äºº", 5: "æ ‘", 6: "å±‹", 
            7: "æ¡¥", 8: "èŠ±", 9: "é¸Ÿ", 10: "å…½"
        }

    def __call__(self, attn, hidden_states, encoder_hidden_states=None, attention_mask=None, **kwargs):
        batch_size, sequence_length, _ = hidden_states.shape
        
        query = attn.to_q(hidden_states)
        encoder_hidden_states = encoder_hidden_states if encoder_hidden_states is not None else hidden_states
        key = attn.to_k(encoder_hidden_states)
        value = attn.to_v(encoder_hidden_states)

        query = attn.head_to_batch_dim(query)
        key = attn.head_to_batch_dim(key)
        value = attn.head_to_batch_dim(value)

        attention_probs = attn.get_attention_scores(query, key, attention_mask)

        # === æ€åŠ¿é”šå®š (Gestalt Anchoring) ===
        tokens = self.tokenizer.encode(self.prompt)
        res = int(np.sqrt(attention_probs.shape[1])) # åŠ¨æ€è·å–åˆ†è¾¨ç‡
        h, w = res, res
        
        for item in self.layout:
            cls_id = int(item[0])
            keyword = self.class_to_keyword.get(cls_id, None)
            if not keyword: continue
            
            # [V8.0] æå–æ•°æ®é©±åŠ¨çš„æ€åŠ¿å‚æ•°
            cx, cy, bw, bh = item[1], item[2], item[3], item[4]
            if len(item) >= 7:
                bx, by = item[5], item[6] # Bias Shift
            else:
                bx, by = 0.0, 0.0
            
            keyword_token_ids = self.tokenizer.encode(keyword, add_special_tokens=False)
            token_indices = [i for i, t in enumerate(tokens) if t in keyword_token_ids]
            
            if not token_indices: continue

            # [Alignment Check] å¿…é¡»ä¸ ink_mask.py (V8.6) çš„ä¸­å¿ƒé€»è¾‘ä¸€è‡´
            x_c, y_c = (cx + bx * 0.15) * w, (cy + by * 0.15) * h
            
            x1, y1 = int(x_c - (bw/2)*w), int(y_c - (bh/2)*h)
            x2, y2 = int(x_c + (bw/2)*w), int(y_c + (bh/2)*h)
            
            x1, y1 = max(0, x1), max(0, y1)
            x2, y2 = min(w, x2), min(h, y2)

            if x2 > x1 and y2 > y1:
                for idx in token_indices:
                    if idx >= attention_probs.shape[-1]: continue
                    mask = torch.zeros((h, w), device=self.device)
                    # å¢å¼ºæ ¸å¿ƒåŒºåŸŸçš„æ³¨æ„åŠ›
                    mask[y1:y2, x1:x2] = self.scale
                    mask_flat = mask.flatten()
                    attention_probs[:, :, idx] += mask_flat * attention_probs[:, :, idx]

        hidden_states = torch.bmm(attention_probs, value)
        hidden_states = attn.batch_to_head_dim(hidden_states)
        hidden_states = attn.to_out[0](hidden_states)
        hidden_states = attn.to_out[1](hidden_states)

        return hidden_states

# =============================================================
# End-to-End Generator (V8.8 Updated)
# =============================================================
class EndToEndGenerator:
    def __init__(self, args):
        self.args = args
        self.device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
        print(f"Loading End-to-End System V8.8 on {self.device}...")

        # 1. è½½å…¥é…ç½® (Stage 1)
        config_path = os.path.join(project_root, "configs", "default.yaml")
        if not os.path.exists(config_path):
            print(f"[Warning] Config not found at {config_path}. Using internal defaults.")
            model_cfg = {'hidden_size': 768, 'bb_size': 128, 'decoder_layers': 6, 'decoder_heads': 8, 'latent_dim': 64}
        else:
            with open(config_path, "r", encoding="utf-8") as f:
                config = yaml.safe_load(f)
            model_cfg = config.get('model', {})

        # 2. åˆå§‹åŒ– Stage 1 (Poem2Layout)
        print("[Stage 1] Loading Layout Generator...")
        self.tokenizer = BertTokenizer.from_pretrained(args.bert_path)
        
        self.layout_model = Poem2LayoutGenerator(
            bert_path=args.bert_path,
            num_classes=9,
            hidden_size=model_cfg.get('hidden_size', 768),
            bb_size=model_cfg.get('bb_size', 128),
            decoder_layers=model_cfg.get('decoder_layers', 6),
            decoder_heads=model_cfg.get('decoder_heads', 8),
            latent_dim=model_cfg.get('latent_dim', 64),
            gestalt_loss_weight=2.0, 
            dropout=0.0
        )
        
        # åŠ è½½ Layout æƒé‡
        if os.path.exists(args.stage1_checkpoint):
            checkpoint = torch.load(args.stage1_checkpoint, map_location=self.device)
            state_dict = checkpoint['model_state_dict'] if 'model_state_dict' in checkpoint else checkpoint
            state_dict = {k.replace('module.', ''): v for k, v in state_dict.items()}
            self.layout_model.load_state_dict(state_dict, strict=False)
            print("âœ… Stage 1 Model loaded.")
        else:
            print(f"âŒ Stage 1 Checkpoint not found: {args.stage1_checkpoint}")
            
        self.layout_model.to(self.device).eval()

        # 3. åˆå§‹åŒ– Stage 2 å·¥å…·
        self.width = 512
        self.height = 512
        self.ink_gen = InkWashMaskGenerator(width=self.width, height=self.height) 

        # 4. åŠ è½½ Stable Diffusion + ControlNet (å•æµ V8.7)
        print(f"[Stage 2] Loading Single-Stream ControlNet & Taiyi...")
        
        # [CHANGE] ç°åœ¨æ˜¯å•æµ ControlNet
        cnet_path = os.path.join(args.stage2_checkpoint, "controlnet_structure")
        try:
            controlnet = ControlNetModel.from_pretrained(cnet_path, torch_dtype=torch.float16)
        except OSError:
            print(f"âŒ ControlNet not found at {cnet_path}. Did training finish?")
            sys.exit(1)

        self.pipe = StableDiffusionControlNetPipeline.from_pretrained(
            args.base_model_path, 
            controlnet=controlnet, # å•æµ
            torch_dtype=torch.float16,
            safety_checker=None 
        )

        # åŠ è½½ LoRA
        lora_path = os.path.join(args.stage2_checkpoint, "unet_lora")
        if os.path.exists(lora_path):
            try:
                self.pipe.load_lora_weights(lora_path)
                print(f"âœ… LoRA loaded from {lora_path} (Strong Style Binding)")
            except Exception as e:
                print(f"âš ï¸ LoRA load failed: {e}")
        else:
            print(f"âš ï¸ LoRA path not found: {lora_path}")
        
        self.pipe.to(self.device)
        self.pipe.enable_model_cpu_offload()

    def infer(self, poem, seed=2024, output_name=None):
        print(f"\nğŸ¨ Generating for: {poem}")
        torch.manual_seed(seed)
        np.random.seed(seed)
        
        save_dir = Path(self.args.output_dir) / f"{poem[:10]}_{seed}"
        save_dir.mkdir(parents=True, exist_ok=True)

        # === Step 1: Layout Generation ===
        layout_list = greedy_decode_poem_layout(
            self.layout_model, self.tokenizer, poem, 
            max_elements=30, device=self.device.type, mode='sample', top_k=5
        )
        
        if not layout_list:
            print("âš ï¸ No layout generated.")
            return

        layout = np.array(layout_list)

        # === Step 2: Visualize Layout ===
        draw_layout(layout, f"Layout: {poem}", str(save_dir / "01_layout.png"))

        # === Step 3: Textured Ink Mask (V8.6) ===
        ink_mask = self.ink_gen.convert_boxes_to_mask(layout)
        ink_mask.save(save_dir / "02_ink_mask.png")

        # === Step 4: Attention Injection ===
        attn_proc = PoemInkAttentionProcessor(
            dynamic_layout=layout, 
            tokenizer=self.pipe.tokenizer, 
            prompt=poem, 
            device=self.device,
            scale=8.0 
        )
        self.pipe.unet.set_attn_processor(attn_proc)

        # === Step 5: Diffusion Generation ===
        # [CRITICAL CHANGE] V8.8: çº¯å‡€ Prompt ç­–ç•¥
        # æ—¢ç„¶ LoRA å·²ç»å¼ºåŠ›ç»‘å®šäº†é£æ ¼ï¼Œè¿™é‡Œåªç”¨åŸè¯—
        prompt = poem 
        
        # Negative prompt ä¾ç„¶é‡è¦ï¼Œç”¨äºæ’é™¤ç…§ç‰‡è´¨æ„Ÿ
        neg_prompt = "ä½è´¨é‡ï¼Œæ¨¡ç³Šï¼Œè‰²å½©æ–‘é©³ï¼Œè¾¹æ¡†ï¼Œæ°´å°ï¼Œæ–‡å­—ï¼Œç°ä»£å»ºç­‘ï¼Œç…§ç‰‡çœŸå®æ„Ÿï¼Œå†™å®é£æ ¼ï¼Œå½©è‰²ç…§ç‰‡"
        
        generator = torch.Generator(device=self.device).manual_seed(seed)
        
        image = self.pipe(
            prompt=prompt, 
            negative_prompt=neg_prompt,
            image=ink_mask, # å•æµè¾“å…¥
            num_inference_steps=35, 
            controlnet_conditioning_scale=1.0, # ç»“æ„æƒé‡ï¼šV8.7 å»ºè®® 1.0ï¼Œç»™ LoRA æ›´å¤šç©ºé—´
            guidance_scale=7.5, 
            generator=generator
        ).images[0]
        
        final_name = output_name if output_name else "03_final_painting.png"
        image.save(save_dir / final_name)
        print(f"âœ… Result saved to: {save_dir}/{final_name}")

def main():
    parser = argparse.ArgumentParser()
    # é»˜è®¤è·¯å¾„é…ç½® (å·²æ›´æ–°ä¸ºä½ çš„ V8.7 è·¯å¾„)
    parser.add_argument("--bert_path", type=str, default="/home/610-sty/huggingface/bert-base-chinese")
    # Stage 1 ä¿æŒä¸å˜ (RL Best)
    parser.add_argument("--stage1_checkpoint", type=str, default="/home/610-sty/layout2paint3/outputs/train_v7_gestal_rl/rl_best_reward.pth")
    
    # [UPDATE] Stage 2 æŒ‡å‘æ–°çš„ V8.7 å¼ºç»‘å®šæ¨¡å‹ç›®å½•
    parser.add_argument("--stage2_checkpoint", type=str, default="/home/610-sty/layout2paint3/outputs/taiyi_ink_controlnet_v2")
    
    parser.add_argument("--base_model_path", type=str, default="/home/610-sty/huggingface/Taiyi-Stable-Diffusion-1B-Chinese-v0.1")
    parser.add_argument("--output_dir", type=str, default="inference_results_v8_7")
    
    parser.add_argument("--poem", type=str, default="æ˜æœˆæ¾é—´ç…§ï¼Œæ¸…æ³‰çŸ³ä¸Šæµã€‚", help="Input poem")
    parser.add_argument("--seed", type=int, default=2024)
    
    args = parser.parse_args()
    
    # å®ä¾‹åŒ–å¹¶è¿è¡Œ
    engine = EndToEndGenerator(args)
    engine.infer(args.poem, args.seed)

if __name__ == "__main__":
    main()