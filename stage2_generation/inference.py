# File: scripts/infer.py (V9.5: End-to-End Smooth Gestalt Inference)

import sys
import os
import argparse
import torch
import numpy as np
import yaml
from PIL import Image
from transformers import BertTokenizer
from pathlib import Path
from diffusers import StableDiffusionControlNetPipeline, ControlNetModel

# === è·¯å¾„é…ç½® & å¯¼å…¥ (å®Œæ•´ä¿ç•™) ===
current_file_path = os.path.abspath(__file__)
# å‡è®¾è„šæœ¬åœ¨ scripts/ æˆ– stage2_generation/ ç›®å½•ä¸‹ï¼Œå‘ä¸Šæ‰¾ä¸¤çº§åˆ°é¡¹ç›®æ ¹ç›®å½•
project_root = os.path.dirname(os.path.dirname(current_file_path))
if project_root not in sys.path:
    sys.path.insert(0, project_root)

# å¯¼å…¥é¡¹ç›®ç»„ä»¶
try:
    from models.poem2layout import Poem2LayoutGenerator
    from inference.greedy_decode import greedy_decode_poem_layout
    # ç¡®ä¿ ink_mask æ˜¯ V8.6+ æ”¯æŒçº¹ç†çš„ç‰ˆæœ¬
    from stage2_generation.utils.ink_mask import InkWashMaskGenerator
    from data.visualize import draw_layout
except ImportError as e:
    print(f"[Error] æ¨¡å—å¯¼å…¥å¤±è´¥: {e}")
    print(f"å½“å‰ sys.path: {sys.path}")
    sys.exit(1)

# =============================================================
# [V9.5 ç»„ä»¶] æ€åŠ¿æ„ŸçŸ¥æ³¨æ„åŠ›å¤„ç†å™¨ (PoemInkAttentionProcessor)
# =============================================================
class PoemInkAttentionProcessor:
    """
    V9.5 æ ¸å¿ƒï¼šå°† 9 ç»´å¸ƒå±€ä¸­çš„ç‰©ç†æ€åŠ¿é€šè¿‡é«˜æ–¯èƒ½é‡åœºæ³¨å…¥åˆ° Cross-Attention ä¸­ã€‚
    ç¡®ä¿ç”Ÿæˆçš„ç”»é¢ç¬”è§¦ä¸ InkMask çš„åŠ¨æ€å¢¨è¿¹ä½ç½®ä¸€è‡´ï¼Œä¸”è¾¹ç¼˜è‡ªç„¶è¡°å‡ã€‚
    """
    def __init__(self, dynamic_layout, tokenizer, prompt, device, scale=5.0):
        # dynamic_layout: [N, 9] -> (cls, cx, cy, w, h, bx, by, rot, flow)
        self.layout = dynamic_layout  
        self.tokenizer = tokenizer
        self.prompt = prompt
        self.device = device
        self.scale = scale 

        self.class_to_keyword = {
            2: "å±±", 3: "æ°´", 4: "äºº", 5: "æ ‘", 6: "å±‹", 
            7: "æ¡¥", 8: "èŠ±", 9: "é¸Ÿ", 10: "å…½"
        }

    def __call__(self, attn, hidden_states, encoder_hidden_states=None, attention_mask=None, **kwargs):
        batch_size, sequence_length, _ = hidden_states.shape
        
        query = attn.to_q(hidden_states)
        encoder_hidden_states = encoder_hidden_states if encoder_hidden_states is not None else hidden_states
        key = attn.to_k(encoder_hidden_states)
        value = attn.to_v(encoder_hidden_states)

        query = attn.head_to_batch_dim(query)
        key = attn.head_to_batch_dim(key)
        value = attn.head_to_batch_dim(value)

        attention_probs = attn.get_attention_scores(query, key, attention_mask)

        # === æ€åŠ¿èƒ½é‡åœºé”šå®š (Gestalt Energy Anchoring) [V9.5 ä¿®æ”¹] ===
        tokens = self.tokenizer.encode(self.prompt)
        res = int(np.sqrt(attention_probs.shape[1])) # åŠ¨æ€è·å–åˆ†è¾¨ç‡
        h, w = res, res
        
        # é¢„è®¡ç®—åæ ‡ç½‘æ ¼
        yy, xx = torch.meshgrid(
            torch.arange(h, device=self.device), 
            torch.arange(w, device=self.device), 
            indexing='ij'
        )
        
        for item in self.layout:
            cls_id = int(item[0])
            keyword = self.class_to_keyword.get(cls_id, None)
            if not keyword: continue
            
            # æå–æ€åŠ¿å‚æ•°
            cx, cy, bw, bh = item[1], item[2], item[3], item[4]
            bx, by = item[5], item[6] if len(item) >= 7 else (0.0, 0.0)
            
            keyword_token_ids = self.tokenizer.encode(keyword, add_special_tokens=False)
            token_indices = [i for i, t in enumerate(tokens) if t in keyword_token_ids]
            
            if not token_indices: continue

            # 1. è®¡ç®—å¯¹é½ä¸­å¿ƒ (ä¸è®­ç»ƒç«¯ä¸€è‡´ï¼š0.15 åç§»ç³»æ•°)
            x_c, y_c = (cx + bx * 0.15) * w, (cy + by * 0.15) * h
            
            # 2. è®¡ç®—æ ‡å‡†å·® (åŸºäºç‰©ä½“å°ºå¯¸ï¼Œ/4 ç¡®ä¿åœºå¼ºå¹³æ»‘)
            sigma = ((bw * w + bh * h) / 4.0) + 1e-6
            
            # 3. ç”Ÿæˆé«˜æ–¯èƒ½é‡åœºæ©ç 
            dist_sq = (xx - x_c)**2 + (yy - y_c)**2
            gauss_mask = torch.exp(-dist_sq / (2 * sigma**2)) * self.scale
            mask_flat = gauss_mask.flatten()

            # 4. è½¯æ³¨å…¥æ³¨æ„åŠ›çŸ©é˜µ
            for idx in token_indices:
                if idx >= attention_probs.shape[-1]: continue
                attention_probs[:, :, idx] += mask_flat * attention_probs[:, :, idx]

        hidden_states = torch.bmm(attention_probs, value)
        hidden_states = attn.batch_to_head_dim(hidden_states)
        hidden_states = attn.to_out[0](hidden_states)
        hidden_states = attn.to_out[1](hidden_states)

        return hidden_states

# =============================================================
# End-to-End Generator (V8.8 Updated)
# =============================================================
class EndToEndGenerator:
    def __init__(self, args):
        self.args = args
        self.device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
        print(f"Loading End-to-End System V9.5 on {self.device}...")

        # 1. è½½å…¥é…ç½® (Stage 1)
        config_path = os.path.join(project_root, "configs", "default.yaml")
        if not os.path.exists(config_path):
            print(f"[Warning] Config not found at {config_path}. Using internal defaults.")
            model_cfg = {'hidden_size': 768, 'bb_size': 128, 'decoder_layers': 6, 'decoder_heads': 8, 'latent_dim': 64}
        else:
            with open(config_path, "r", encoding="utf-8") as f:
                config = yaml.safe_load(f)
            model_cfg = config.get('model', {})

        # 2. åˆå§‹åŒ– Stage 1 (Poem2Layout)
        print("[Stage 1] Loading Layout Generator...")
        self.tokenizer = BertTokenizer.from_pretrained(args.bert_path)
        
        self.layout_model = Poem2LayoutGenerator(
            bert_path=args.bert_path,
            num_classes=9,
            hidden_size=model_cfg.get('hidden_size', 768),
            bb_size=model_cfg.get('bb_size', 128),
            decoder_layers=model_cfg.get('decoder_layers', 6),
            decoder_heads=model_cfg.get('decoder_heads', 8),
            latent_dim=model_cfg.get('latent_dim', 64),
            gestalt_loss_weight=2.0, 
            dropout=0.0
        )
        
        # åŠ è½½ Layout æƒé‡
        if os.path.exists(args.stage1_checkpoint):
            checkpoint = torch.load(args.stage1_checkpoint, map_location=self.device)
            state_dict = checkpoint['model_state_dict'] if 'model_state_dict' in checkpoint else checkpoint
            state_dict = {k.replace('module.', ''): v for k, v in state_dict.items()}
            self.layout_model.load_state_dict(state_dict, strict=False)
            print("âœ… Stage 1 Model loaded.")
        else:
            print(f"âŒ Stage 1 Checkpoint not found: {args.stage1_checkpoint}")
            
        self.layout_model.to(self.device).eval()

        # 3. åˆå§‹åŒ– Stage 2 å·¥å…·
        self.width = 512
        self.height = 512
        self.ink_gen = InkWashMaskGenerator(width=self.width, height=self.height) 

        # 4. åŠ è½½ Stable Diffusion + ControlNet
        print(f"[Stage 2] Loading Single-Stream ControlNet & Taiyi...")
        
        cnet_path = os.path.join(args.stage2_checkpoint, "controlnet_structure")
        try:
            controlnet = ControlNetModel.from_pretrained(cnet_path, torch_dtype=torch.float16)
        except OSError:
            print(f"âŒ ControlNet not found at {cnet_path}. Did training finish?")
            sys.exit(1)

        self.pipe = StableDiffusionControlNetPipeline.from_pretrained(
            args.base_model_path, 
            controlnet=controlnet,
            torch_dtype=torch.float16,
            safety_checker=None 
        )

        # åŠ è½½ LoRA
        lora_path = os.path.join(args.stage2_checkpoint, "unet_lora")
        if os.path.exists(lora_path):
            try:
                self.pipe.load_lora_weights(lora_path)
                print(f"âœ… LoRA loaded from {lora_path} (Strong Style Binding)")
            except Exception as e:
                print(f"âš ï¸ LoRA load failed: {e}")
        else:
            print(f"âš ï¸ LoRA path not found: {lora_path}")
        
        self.pipe.to(self.device)
        self.pipe.enable_model_cpu_offload()

    def infer(self, poem, seed=2024, output_name=None):
        print(f"\nğŸ¨ Generating for: {poem}")
        torch.manual_seed(seed)
        np.random.seed(seed)
        
        save_dir = Path(self.args.output_dir) / f"{poem[:10]}_{seed}"
        save_dir.mkdir(parents=True, exist_ok=True)

        # === Step 1: Layout Generation ===
        layout_list = greedy_decode_poem_layout(
            self.layout_model, self.tokenizer, poem, 
            max_elements=30, device=self.device.type, mode='sample', top_k=5
        )
        
        if not layout_list:
            print("âš ï¸ No layout generated.")
            return

        layout = np.array(layout_list)

        # === Step 2: Visualize Layout ===
        draw_layout(layout, f"Layout: {poem}", str(save_dir / "01_layout.png"))

        # === Step 3: Textured Ink Mask ===
        ink_mask = self.ink_gen.convert_boxes_to_mask(layout)
        ink_mask.save(save_dir / "02_ink_mask.png")

        # === Step 4: Attention Injection (V9.5 Soft Energy) ===
        attn_proc = PoemInkAttentionProcessor(
            dynamic_layout=layout, 
            tokenizer=self.pipe.tokenizer, 
            prompt=poem, 
            device=self.device,
            scale=5.0  # å»ºè®®ç”± 8.0 é™è‡³ 5.0ï¼Œé…åˆé«˜æ–¯åœºè¾¾åˆ°æœ€ä½³å¹³è¡¡
        )
        self.pipe.unet.set_attn_processor(attn_proc)

        # === Step 5: Diffusion Generation ===
        prompt = poem 
        neg_prompt = "ä½è´¨é‡ï¼Œæ¨¡ç³Šï¼Œè‰²å½©æ–‘é©³ï¼Œè¾¹æ¡†ï¼Œæ°´å°ï¼Œæ–‡å­—ï¼Œç°ä»£å»ºç­‘ï¼Œç…§ç‰‡çœŸå®æ„Ÿï¼Œå†™å®é£æ ¼ï¼Œå½©è‰²ç…§ç‰‡"
        
        generator = torch.Generator(device=self.device).manual_seed(seed)
        
        image = self.pipe(
            prompt=prompt, 
            negative_prompt=neg_prompt,
            image=ink_mask,
            num_inference_steps=35, 
            controlnet_conditioning_scale=1.0, 
            guidance_scale=7.5, 
            generator=generator
        ).images[0]
        
        final_name = output_name if output_name else "03_final_painting.png"
        image.save(save_dir / final_name)
        print(f"âœ… Result saved to: {save_dir}/{final_name}")

def main():
    parser = argparse.ArgumentParser()
    parser.add_argument("--bert_path", type=str, default="/home/610-sty/huggingface/bert-base-chinese")
    parser.add_argument("--stage1_checkpoint", type=str, required=True)
    parser.add_argument("--stage2_checkpoint", type=str, required=True)
    parser.add_argument("--base_model_path", type=str, default="/home/610-sty/huggingface/Taiyi-Stable-Diffusion-1B-Chinese-v0.1")
    parser.add_argument("--output_dir", type=str, default="inference_results_v9_5")
    parser.add_argument("--poem", type=str, default="æ˜æœˆæ¾é—´ç…§ï¼Œæ¸…æ³‰çŸ³ä¸Šæµã€‚", help="Input poem")
    parser.add_argument("--seed", type=int, default=2024)
    
    args = parser.parse_args()
    
    # å®ä¾‹åŒ–å¹¶è¿è¡Œ
    engine = EndToEndGenerator(args)
    engine.infer(args.poem, args.seed)

if __name__ == "__main__":
    main()