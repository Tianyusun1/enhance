#!/bin/bash

# ================= é…ç½®åŒºåŸŸ =================
# GPU åŠ¨æ€è°ƒåº¦å·²å¯ç”¨ï¼Œç¦æ­¢æ‰‹åŠ¨è®¾ç½® CUDA_VISIBLE_DEVICES é˜²æ­¢å†²çª
# export CUDA_VISIBLE_DEVICES=0 

# ä¼˜åŒ–æ˜¾å­˜åˆ†é…ç­–ç•¥
export PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True

PROJECT_ROOT=$(pwd)

# [ç¼“å­˜è®¾ç½®]
export HF_HOME="$PROJECT_ROOT/.hf_cache"
mkdir -p "$HF_HOME"

# [è¾“å‡ºä¸Žæ•°æ®è·¯å¾„]
OUTPUT_DIR="/home/610-sty/layout2paint3/outputs/taiyi_shanshui_v9_3_rank32"
DATA_DIR="/home/610-sty/layout2paint3/taiyi_dataset_v8_8_deep_style" 

# [åŸºç¡€æ¨¡åž‹è·¯å¾„]
MODEL_NAME="/home/610-sty/huggingface/Taiyi-Stable-Diffusion-1B-Chinese-v0.1"

# Accelerate é…ç½®æ–‡ä»¶è·¯å¾„
ACCELERATE_CONFIG="stage2_generation/configs/accelerate_config.yaml"

# ===========================================

# 1. å®‰å…¨æ£€æŸ¥
if [ ! -f "$DATA_DIR/train.jsonl" ]; then
    echo "âŒ é”™è¯¯: åœ¨ $DATA_DIR ä¸­æ‰¾ä¸åˆ° train.jsonl"
    exit 1
fi

# 2. æ£€æŸ¥ Accelerate é…ç½®
if [ ! -f "$ACCELERATE_CONFIG" ]; then
    echo "âš ï¸ ç”Ÿæˆé»˜è®¤é…ç½®..."
    mkdir -p $(dirname "$ACCELERATE_CONFIG")
    cat > "$ACCELERATE_CONFIG" <<EOF
compute_environment: LOCAL_MACHINE
distributed_type: NO
mixed_precision: fp16
num_machines: 1
num_processes: 1
use_cpu: false
EOF
fi

# 3. å¯åŠ¨è®­ç»ƒ (V9.3 ç¨³å¥ç‰ˆ)
echo "========================================================"
echo "ðŸš€ å¯åŠ¨ Stage 2 V9.3 è®­ç»ƒ (Rank 32 ç¨³å®šç‰ˆ)"
echo "   ç­–ç•¥äº®ç‚¹: LoRA Rank=32 | lambda_struct=0.05 | Smart Freeze"
echo "========================================================"

accelerate launch --config_file "$ACCELERATE_CONFIG" --mixed_precision="fp16" stage2_generation/scripts/train_taiyi.py \
  --pretrained_model_name_or_path="$MODEL_NAME" \
  --train_data_dir="$DATA_DIR" \
  --output_dir="$OUTPUT_DIR" \
  --resolution=512 \
  --train_batch_size=4 \
  --gradient_accumulation_steps=1 \
  --num_train_epochs=40 \
  --checkpointing_steps=10000 \
  --mixed_precision="fp16" \
  \
  --learning_rate=2e-5 \
  --learning_rate_lora=1e-4 \
  \
  --lambda_struct=0.05 \
  \
  --lora_rank=32 \
  --lora_alpha_ratio=1.0 \
  \
  --smart_freeze

echo "âœ… è®­ç»ƒè„šæœ¬æ‰§è¡Œå®Œæ¯•ã€‚æ—¥å¿—: $OUTPUT_DIR/train_loss_history.txt"