# File: stage2_generation/scripts/prepare_data_taiyi.py (V8.8: Enhanced Shanshui Texture Mode)

import sys
import os
import argparse
import pandas as pd
import json
from pathlib import Path
from tqdm import tqdm
from PIL import Image
import numpy as np

# === è·¯å¾„è®¾ç½® (ä¿æŒåŸæœ‰é€»è¾‘) ===
current_file_path = os.path.abspath(__file__)
stage2_root = os.path.dirname(os.path.dirname(current_file_path))
project_root = os.path.dirname(stage2_root)
if project_root not in sys.path: sys.path.insert(0, project_root)
if stage2_root not in sys.path: sys.path.append(stage2_root)

# å¯¼å…¥å·²ç»ä¿®æ”¹ä¸º V7.0 ç‰ˆçš„å·¥å…·
try:
    from stage2_generation.utils.ink_mask import InkWashMaskGenerator
except ImportError:
    print("âŒ æ— æ³•å¯¼å…¥ InkWashMaskGeneratorï¼Œè¯·æ£€æŸ¥è·¯å¾„ã€‚")
    sys.exit(1)

# [NEW] å¯¼å…¥ Stage 1 çš„è§†è§‰æ€åŠ¿æå–å™¨
try:
    from data.dataset import VisualGestaltExtractor
except ImportError:
    print("âŒ æ— æ³•å¯¼å…¥ VisualGestaltExtractorï¼Œè¯·æ£€æŸ¥ data/dataset.py æ˜¯å¦å­˜åœ¨ã€‚")
    sys.exit(1)

def parse_args():
    parser = argparse.ArgumentParser(description="Taiyi V8.8: å‡†å¤‡åŒ…å«æ·±åº¦çº¹ç†è´¨æ„Ÿçš„æ•°æ®é›†")
    default_xlsx = "/home/610-sty/layout2paint/dataset/6800poems.xlsx"
    default_img_dir = "/home/610-sty/layout2paint/dataset/6800"
    default_lbl_dir = "/home/610-sty/layout2paint/dataset/6800/JPEGImages-pre_new_txt"
    
    parser.add_argument("--xlsx_path", type=str, default=default_xlsx)
    parser.add_argument("--images_dir", type=str, default=default_img_dir)
    parser.add_argument("--labels_dir", type=str, default=default_lbl_dir)
    parser.add_argument("--output_dir", type=str, default="./taiyi_dataset_v8_8_deep_style") 
    parser.add_argument("--resolution", type=int, default=512) 
    return parser.parse_args()

def main():
    args = parse_args()
    os.makedirs(os.path.join(args.output_dir, "images"), exist_ok=True)
    os.makedirs(os.path.join(args.output_dir, "conditioning_images"), exist_ok=True)
    
    # 1. åˆå§‹åŒ– Mask ç”Ÿæˆå™¨ (ä¿æŒåŸæœ‰è®¾ç½®ï¼Œå‡†å¤‡åç»­è°ƒç”¨)
    ink_generator = InkWashMaskGenerator(width=args.resolution, height=args.resolution)
    
    # 2. åˆå§‹åŒ–æ€åŠ¿æå–å™¨ (ä¿æŒåŸæœ‰é€»è¾‘)
    gestalt_extractor = VisualGestaltExtractor()
    print("âœ… Visual Gestalt Extractor (Pixel-Level) initialized.")
    
    df = pd.read_excel(args.xlsx_path)
    
    metadata_entries = []
    
    # åŸºç¡€é£æ ¼è¯ (æŒ‰è¦æ±‚ä¿æŒä¸ºç©ºï¼Œä¸ä½¿ç”¨é£æ ¼è§¦å‘è¯)
    style_suffix = ""

    print(f"å¼€å§‹å¤„ç†æ•°æ®ï¼Œå…± {len(df)} æ¡...")
    for idx, row in tqdm(df.iterrows(), total=len(df)):
        try:
            raw_img_name = str(row['image']).strip()
            poem = str(row['poem']).strip()
            img_stem = Path(raw_img_name).stem
            
            src_img_path = os.path.join(args.images_dir, raw_img_name)
            if not os.path.exists(src_img_path): continue
            
            label_path = os.path.join(args.labels_dir, f"{img_stem}.txt")
            if not os.path.exists(label_path): continue

            # 3. è¯»å– Box å¹¶æå–çœŸå®æ€åŠ¿ (ä¿ç•™åŸæœ‰æå–æµç¨‹)
            boxes_9d = [] # å­˜å‚¨ 9 ç»´æ•°æ® [cls, cx, cy, w, h, bx, by, rot, flow]
            
            with open(label_path, 'r') as f:
                for line in f:
                    parts = line.strip().split()
                    if len(parts) >= 5: 
                        cls_id, cx, cy, w, h = map(float, parts[:5])
                        
                        # [æ ¸å¿ƒé€»è¾‘] å®æ—¶æå– Gestalt å‚æ•°
                        g_params, valid = gestalt_extractor.extract(src_img_path, [cx, cy, w, h])
                        
                        if valid < 0.5:
                            g_params = [0.0, 0.0, 0.0, 0.0]
                            
                        full_box = [cls_id, cx, cy, w, h] + g_params
                        boxes_9d.append(full_box)
            
            if not boxes_9d: continue

            # 4. ç”Ÿæˆå½©è‰²åŠ¿èƒ½åœº Mask
            # [MODIFIED] å¼ºåˆ¶å¼€å¯ texture æ¸²æŸ“æ¨¡å¼
            # ç†ç”±ï¼šä¸ºäº†è®©æ¨¡å‹åœ¨ä¸åŠ å…³é”®è¯çš„æƒ…å†µä¸‹å­¦ä¹ ç”»é£ï¼ŒMask å¿…é¡»å…·å¤‡å¢¨è‰²æ·±æµ…å’Œæ´‡æ•£çš„ç°åº¦è´¨æ„Ÿã€‚
            # è¿™æœ‰åŠ©äº ControlNet å¼•å¯¼æ¨¡å‹ç”Ÿæˆâ€œç¬”è§¦â€è€Œéâ€œè‰²å—â€ã€‚
            cond_img = ink_generator.convert_boxes_to_mask(boxes_9d) 
            
            cond_img_name = f"{img_stem}_ink_v8_8.png"
            cond_img.save(os.path.join(args.output_dir, "conditioning_images", cond_img_name))
            
            # 5. å¤„ç†åŸå›¾ (ä¿æŒåŸæœ‰å¤„ç†)
            target_img = Image.open(src_img_path).convert("RGB")
            target_img = target_img.resize((args.resolution, args.resolution), Image.BICUBIC)
            target_img_name = f"{img_stem}.jpg"
            target_img.save(os.path.join(args.output_dir, "images", target_img_name))

            # 6. æ„é€ çº¯å‡€ä¸­æ–‡ Prompt (æŒ‰è¦æ±‚ä¸å«é£æ ¼åç¼€)
            chinese_prompt = f"{poem}"

            metadata_entries.append({
                "image": f"images/{target_img_name}",
                "conditioning_image": f"conditioning_images/{cond_img_name}",
                "text": chinese_prompt
            })
            
        except Exception as e:
            print(f"Error processing {img_stem}: {e}")
            continue

    # ä¿å­˜ JSONL
    output_jsonl = os.path.join(args.output_dir, "train.jsonl")
    with open(output_jsonl, 'w', encoding='utf-8') as f:
        for entry in metadata_entries:
            json.dump(entry, f, ensure_ascii=False)
            f.write('\n')
            
    print(f"âœ¨ V8.8 æ·±åº¦çº¹ç†æ•°æ®é›†å‡†å¤‡å®Œæˆï¼")
    print(f"ğŸ“‚ è¾“å‡ºç›®å½•: {args.output_dir}")
    print(f"ğŸ“„ ç´¢å¼•æ–‡ä»¶: {output_jsonl}")
    print("âš ï¸  ç­–ç•¥æç¤º: å·²å¼ºåŒ– Mask çº¹ç†å±‚æ¬¡ï¼Œé…åˆ train_taiyi.py çš„æ·±åº¦è§£å†»ç­–ç•¥ä½¿ç”¨ã€‚")

if __name__ == "__main__":
    main()