# File: stage2_generation/scripts/prepare_data_taiyi.py (V9.1: Final Robust Edition)

import sys
import os
import argparse
import pandas as pd
import json
from pathlib import Path
from tqdm import tqdm
from PIL import Image
import numpy as np
import cv2  # å¼•å…¥ OpenCV è¿›è¡Œå½¢æ€å­¦è®¡ç®—

# === è·¯å¾„è®¾ç½® (ä¿æŒåŸæœ‰é€»è¾‘) ===
current_file_path = os.path.abspath(__file__)
stage2_root = os.path.dirname(os.path.dirname(current_file_path))
project_root = os.path.dirname(stage2_root)
if project_root not in sys.path: sys.path.insert(0, project_root)
if stage2_root not in sys.path: sys.path.append(stage2_root)

# å¯¼å…¥å·¥å…·
try:
    from stage2_generation.utils.ink_mask import InkWashMaskGenerator
except ImportError:
    print("âŒ æ— æ³•å¯¼å…¥ InkWashMaskGeneratorï¼Œè¯·æ£€æŸ¥è·¯å¾„ã€‚")
    sys.exit(1)

# === [CRITICAL CLASS] æœ¬åœ°å®šä¹‰ä¿®å¤ç‰ˆçš„æ€åŠ¿æå–å™¨ ===
class FixedVisualGestaltExtractor:
    """
    [V9.1 ä¿®å¤ç‰ˆ] è§†è§‰æ€åŠ¿æå–å™¨
    1. ä¿®æ­£ Flow æˆªæ–­é€»è¾‘ï¼Œæ”¯æŒè´Ÿå€¼(æ¯ç¬”)ã€‚
    2. æ”¯æŒä¸­æ–‡è·¯å¾„è¯»å– (cv2.imdecode)ã€‚
    """
    def extract(self, image_path: str, box: list) -> tuple:
        """
        è¾“å…¥: å…¨å›¾è·¯å¾„, å½’ä¸€åŒ– Box [cx, cy, w, h]
        è¾“å‡º: ([bias_x, bias_y, rotation, flow], validity)
        """
        try:
            # 1. å®‰å…¨æ€§æ£€æŸ¥
            if not os.path.exists(image_path):
                return [0.0, 0.0, 0.0, 0.0], 0.0
            
            # [å…³é”®ä¿®å¤] è¯»å–ç°åº¦å›¾ (æ”¯æŒä¸­æ–‡è·¯å¾„)
            try:
                img_array = np.fromfile(image_path, dtype=np.uint8)
                img = cv2.imdecode(img_array, cv2.IMREAD_GRAYSCALE)
            except Exception:
                img = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)

            if img is None:
                return [0.0, 0.0, 0.0, 0.0], 0.0
                
            H, W = img.shape
            cx, cy, w, h = box
            
            # 2. è£åˆ‡ç‰©ä½“ (Crop)
            x1 = int((cx - w/2) * W)
            y1 = int((cy - h/2) * H)
            x2 = int((cx + w/2) * W)
            y2 = int((cy + h/2) * H)
            
            x1, y1 = max(0, x1), max(0, y1)
            x2, y2 = min(W, x2), min(H, y2)
            
            if (x2 - x1) < 2 or (y2 - y1) < 2:
                return [0.0, 0.0, 0.0, 0.0], 0.0
                
            crop = img[y1:y2, x1:x2]
            
            # 3. æ°´å¢¨é¢„å¤„ç†
            ink_map = 255.0 - crop.astype(float)
            ink_map[ink_map < 30] = 0 
            
            total_ink = np.sum(ink_map)
            if total_ink < 100: 
                return [0.0, 0.0, 0.0, 0.0], 0.0

            # === A. è®¡ç®— Bias & Rotation ===
            M = cv2.moments(ink_map.astype(np.float32), binaryImage=False)
            
            bias_x, bias_y = 0.0, 0.0
            rotation = 0.0
            
            if M["m00"] != 0:
                cX = M["m10"] / M["m00"]
                cY = M["m01"] / M["m00"]
                h_crop, w_crop = ink_map.shape
                geo_cX = w_crop / 2.0
                geo_cY = h_crop / 2.0
                
                bias_x = (cX - geo_cX) / (geo_cX + 1e-6)
                bias_y = (cY - geo_cY) / (geo_cY + 1e-6)
                bias_x = np.clip(bias_x, -1.0, 1.0)
                bias_y = np.clip(bias_y, -1.0, 1.0)
                
                mu20 = M["mu20"] / M["m00"]
                mu02 = M["mu02"] / M["m00"]
                mu11 = M["mu11"] / M["m00"]
                theta = 0.5 * np.arctan2(2 * mu11, mu20 - mu02)
                rotation = theta / (np.pi / 2)
            
            # === B. è®¡ç®— Flow (æ”¯æŒè´Ÿå€¼æ¯ç¬”) ===
            h_crop, w_crop = ink_map.shape
            avg_density = total_ink / (w_crop * h_crop * 255.0)
            
            sobelx = cv2.Sobel(crop, cv2.CV_64F, 1, 0, ksize=3)
            sobely = cv2.Sobel(crop, cv2.CV_64F, 0, 1, ksize=3)
            grad_mag = np.sqrt(sobelx**2 + sobely**2)
            avg_grad = np.mean(grad_mag) / 255.0 
            
            raw_flow = avg_density / (avg_grad + 0.01)
            
            # [æ ¸å¿ƒæ˜ å°„é€»è¾‘] Pivot = 0.6
            pivot = 0.6
            if raw_flow > pivot:
                # æ¹¿æ¶¦åŒºé—´ (0, 1]
                flow = (raw_flow - pivot) / (3.0 - pivot + 1e-6)
                flow = np.clip(flow, 0.05, 1.0)
            else:
                # æ¯ç‡¥åŒºé—´ [-1, 0)
                flow = (raw_flow - pivot) / pivot
                flow = np.clip(flow, -1.0, -0.05)
            
            return [float(bias_x), float(bias_y), float(rotation), float(flow)], 1.0
            
        except Exception as e:
            return [0.0, 0.0, 0.0, 0.0], 0.0

def parse_args():
    parser = argparse.ArgumentParser(description="Taiyi V9.1: å‡†å¤‡åŒ…å«æ¯ç¬”è´¨æ„Ÿçš„æ•°æ®é›† (å¼ºå¥è·¯å¾„ç‰ˆ)")
    # è¯·æ ¹æ®å®é™…ç¯å¢ƒç¡®è®¤è·¯å¾„ï¼Œè¿™é‡Œä½¿ç”¨äº† dataset çš„ä¸Šçº§ç›®å½•ä»¥ä¾¿å…¨å±€æ‰«æ
    default_xlsx = "/home/610-sty/layout2paint/dataset/6800poems.xlsx"
    default_img_dir = "/home/610-sty/layout2paint/dataset" 
    default_lbl_dir = "/home/610-sty/layout2paint/dataset/6800/JPEGImages-pre_new_txt"
    
    parser.add_argument("--xlsx_path", type=str, default=default_xlsx)
    parser.add_argument("--images_dir", type=str, default=default_img_dir)
    parser.add_argument("--labels_dir", type=str, default=default_lbl_dir)
    # è¾“å‡ºç›®å½•
    parser.add_argument("--output_dir", type=str, default="./taiyi_dataset_v9_1_robust") 
    parser.add_argument("--resolution", type=int, default=512) 
    return parser.parse_args()

def main():
    args = parse_args()
    os.makedirs(os.path.join(args.output_dir, "images"), exist_ok=True)
    os.makedirs(os.path.join(args.output_dir, "conditioning_images"), exist_ok=True)
    
    # 1. åˆå§‹åŒ– Mask ç”Ÿæˆå™¨
    ink_generator = InkWashMaskGenerator(width=args.resolution, height=args.resolution)
    
    # 2. åˆå§‹åŒ– æ€åŠ¿æå–å™¨
    gestalt_extractor = FixedVisualGestaltExtractor()
    print("âœ… Fixed Visual Gestalt Extractor (V9.1 with Chinese Path Support) initialized.")
    
    # =========================================================
    # [V9.1 æ ¸å¿ƒä¿®å¤] å»ºç«‹å…¨å±€å›¾ç‰‡ç´¢å¼• (Global Image Index)
    # è§£å†³è·¯å¾„æ··ä¹±ã€å­æ–‡ä»¶å¤¹æ‰¾ä¸åˆ°ã€ä¸­æ–‡è·¯å¾„ç­‰é—®é¢˜
    # =========================================================
    print(f"ğŸ” æ­£åœ¨æ‰«æå›¾ç‰‡ç›®å½•å»ºç«‹ç´¢å¼•: {args.images_dir} ...")
    image_index = {}
    scan_count = 0
    # os.walk ä¼šé€’å½’æ‰«ææ‰€æœ‰å­æ–‡ä»¶å¤¹
    for root, dirs, files in os.walk(args.images_dir):
        for file in files:
            if file.lower().endswith(('.jpg', '.jpeg', '.png', '.bmp', '.tiff')):
                # å»ºç«‹ æ–‡ä»¶å -> ç»å¯¹è·¯å¾„ çš„æ˜ å°„
                image_index[file] = os.path.join(root, file)
                scan_count += 1
    print(f"âœ… ç´¢å¼•å»ºç«‹å®Œæˆã€‚å…±æ‰¾åˆ° {scan_count} å¼ å›¾ç‰‡ã€‚")

    df = pd.read_excel(args.xlsx_path)
    metadata_entries = []
    
    success_count = 0
    missing_count = 0

    print(f"ğŸš€ å¼€å§‹å¤„ç†æ•°æ®ï¼Œå…± {len(df)} æ¡...")
    for idx, row in tqdm(df.iterrows(), total=len(df)):
        try:
            raw_img_name = str(row['image']).strip()
            poem = str(row['poem']).strip()
            
            # --- æ™ºèƒ½è·¯å¾„æŸ¥æ‰¾ ---
            src_img_path = None
            
            # ç­–ç•¥ 1: ç»å¯¹è·¯å¾„ä¸”å­˜åœ¨
            if os.path.isabs(raw_img_name) and os.path.exists(raw_img_name):
                src_img_path = raw_img_name
            
            # ç­–ç•¥ 2: ä½¿ç”¨ç´¢å¼•æŸ¥æ‰¾ (æ–‡ä»¶ååŒ¹é…)
            # æå–çº¯æ–‡ä»¶å (ä¾‹å¦‚ "6800/a.jpg" -> "a.jpg")
            if src_img_path is None:
                basename = os.path.basename(raw_img_name)
                if basename in image_index:
                    src_img_path = image_index[basename]
            
            # ç­–ç•¥ 3: ç®€å•æ‹¼æ¥ (Fallback)
            if src_img_path is None:
                fallback = os.path.join(args.images_dir, raw_img_name)
                if os.path.exists(fallback):
                    src_img_path = fallback

            # è¿˜æ˜¯æ‰¾ä¸åˆ°ï¼Ÿè®°å½•å¹¶è·³è¿‡
            if src_img_path is None:
                missing_count += 1
                # print(f"âš ï¸ è·³è¿‡: æ‰¾ä¸åˆ°å›¾ç‰‡ {raw_img_name}") # å¯å–æ¶ˆæ³¨é‡Šä»¥è°ƒè¯•
                continue

            # æ„é€  Label è·¯å¾„ (Label é€šå¸¸å’Œå›¾ç‰‡åŒåï¼Œä½†åœ¨æŒ‡å®šæ–‡ä»¶å¤¹ä¸‹)
            img_stem = Path(src_img_path).stem
            label_path = os.path.join(args.labels_dir, f"{img_stem}.txt")
            if not os.path.exists(label_path): 
                continue

            # 3. è¯»å– Box å¹¶æå–çœŸå®æ€åŠ¿
            boxes_9d = [] 
            
            with open(label_path, 'r') as f:
                for line in f:
                    parts = line.strip().split()
                    if len(parts) >= 5: 
                        cls_id, cx, cy, w, h = map(float, parts[:5])
                        
                        # æå– Flow (åŒ…å«è´Ÿå€¼)
                        g_params, valid = gestalt_extractor.extract(src_img_path, [cx, cy, w, h])
                        
                        # å¦‚æœæå–å¤±è´¥ï¼ˆä¾‹å¦‚å¤ªå°æˆ–ç©ºç™½ï¼‰ï¼Œç»™ä¸€ä¸ªé»˜è®¤æ¹¿æ¶¦å€¼
                        if valid < 0.5:
                            g_params = [0.0, 0.0, 0.0, 0.5] 
                            
                        full_box = [cls_id, cx, cy, w, h] + g_params
                        boxes_9d.append(full_box)
            
            if not boxes_9d: continue

            # 4. ç”Ÿæˆ Mask (å¸¦æ¯ç¬”çº¹ç†)
            cond_img = ink_generator.convert_boxes_to_mask(boxes_9d) 
            cond_img_name = f"{img_stem}_ink_v9.png"
            cond_img.save(os.path.join(args.output_dir, "conditioning_images", cond_img_name))
            
            # 5. å¤„ç†åŸå›¾ (å¤åˆ¶å¹¶ Resize)
            # [Fix] ä½¿ç”¨ cv2 è¯»å–å†è½¬ PILï¼Œç¡®ä¿ä¸­æ–‡è·¯å¾„ä¹Ÿèƒ½è¢«æ­£ç¡®åŠ è½½
            # æ³¨æ„ï¼šcv2 è¯»å–çš„æ˜¯ BGRï¼Œè½¬ PIL å‰éœ€è¦è½¬ RGB
            try:
                img_array = np.fromfile(src_img_path, dtype=np.uint8)
                img_cv = cv2.imdecode(img_array, cv2.IMREAD_COLOR)
                if img_cv is None: continue
                img_rgb = cv2.cvtColor(img_cv, cv2.COLOR_BGR2RGB)
                target_img = Image.fromarray(img_rgb)
            except Exception:
                # Fallback åˆ° PIL è¯»å– (å¦‚æœéä¸­æ–‡è·¯å¾„å¯èƒ½æ›´å¿«)
                target_img = Image.open(src_img_path).convert("RGB")

            target_img = target_img.resize((args.resolution, args.resolution), Image.BICUBIC)
            target_img_name = f"{img_stem}.jpg"
            target_img.save(os.path.join(args.output_dir, "images", target_img_name))

            # 6. æ„é€  Prompt
            chinese_prompt = f"{poem}"

            metadata_entries.append({
                "image": f"images/{target_img_name}",
                "conditioning_image": f"conditioning_images/{cond_img_name}",
                "text": chinese_prompt
            })
            
            success_count += 1
            
        except Exception as e:
            print(f"Error processing {idx}: {e}")
            continue

    # ä¿å­˜ JSONL
    output_jsonl = os.path.join(args.output_dir, "train.jsonl")
    with open(output_jsonl, 'w', encoding='utf-8') as f:
        for entry in metadata_entries:
            json.dump(entry, f, ensure_ascii=False)
            f.write('\n')
            
    print(f"âœ¨ V9.1 æ•°æ®å‡†å¤‡å®Œæˆï¼")
    print(f"âœ… æˆåŠŸå¤„ç†: {success_count} å¼ ")
    if missing_count > 0:
        print(f"âš ï¸ ä¸¢å¤±å›¾ç‰‡: {missing_count} å¼  (è¯·æ£€æŸ¥æ–‡ä»¶åç´¢å¼•)")
    print(f"ğŸ“‚ è¾“å‡ºç›®å½•: {args.output_dir}")

if __name__ == "__main__":
    main()