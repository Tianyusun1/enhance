# File: stage2_generation/scripts/prepare_data_taiyi.py (V9.2: Gestalt Energy Field & Robust Path Edition)

import sys
import os
import argparse
import pandas as pd
import json
from pathlib import Path
from tqdm import tqdm
from PIL import Image
import numpy as np
import cv2  # å¼•å…¥ OpenCV è¿›è¡Œå½¢æ€å­¦è®¡ç®—

# === è·¯å¾„è®¾ç½® (ä¿æŒåŸæœ‰é€»è¾‘) ===
current_file_path = os.path.abspath(__file__)
stage2_root = os.path.dirname(os.path.dirname(current_file_path))
project_root = os.path.dirname(stage2_root)
if project_root not in sys.path: sys.path.insert(0, project_root)
if stage2_root not in sys.path: sys.path.append(stage2_root)

# å¯¼å…¥å·¥å…·
try:
    from stage2_generation.utils.ink_mask import InkWashMaskGenerator
except ImportError:
    print("âŒ æ— æ³•å¯¼å…¥ InkWashMaskGeneratorï¼Œè¯·æ£€æŸ¥è·¯å¾„ã€‚")
    sys.exit(1)

# === [V9.1 ä¿®å¤ç‰ˆ] è§†è§‰æ€åŠ¿æå–å™¨ (å®Œæ•´ä¿ç•™) ===
class FixedVisualGestaltExtractor:
    """
    [V9.1 ä¿®å¤ç‰ˆ] è§†è§‰æ€åŠ¿æå–å™¨
    1. ä¿®æ­£ Flow æˆªæ–­é€»è¾‘ï¼Œæ”¯æŒè´Ÿå€¼(æ¯ç¬”)ã€‚
    2. æ”¯æŒä¸­æ–‡è·¯å¾„è¯»å– (cv2.imdecode)ã€‚
    """
    def extract(self, image_path: str, box: list) -> tuple:
        """
        è¾“å…¥: å…¨å›¾è·¯å¾„, å½’ä¸€åŒ– Box [cx, cy, w, h]
        è¾“å‡º: ([bias_x, bias_y, rotation, flow], validity)
        """
        try:
            # 1. å®‰å…¨æ€§æ£€æŸ¥
            if not os.path.exists(image_path):
                return [0.0, 0.0, 0.0, 0.0], 0.0
            
            # [å…³é”®ä¿®å¤] è¯»å–ç°åº¦å›¾ (æ”¯æŒä¸­æ–‡è·¯å¾„)
            try:
                img_array = np.fromfile(image_path, dtype=np.uint8)
                img = cv2.imdecode(img_array, cv2.IMREAD_GRAYSCALE)
            except Exception:
                img = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)

            if img is None:
                return [0.0, 0.0, 0.0, 0.0], 0.0
                
            H, W = img.shape
            cx, cy, w, h = box
            
            # 2. è£åˆ‡ç‰©ä½“ (Crop)
            x1 = int((cx - w/2) * W)
            y1 = int((cy - h/2) * H)
            x2 = int((cx + w/2) * W)
            y2 = int((cy + h/2) * H)
            
            x1, y1 = max(0, x1), max(0, y1)
            x2, y2 = min(W, x2), min(H, y2)
            
            if (x2 - x1) < 2 or (y2 - y1) < 2:
                return [0.0, 0.0, 0.0, 0.0], 0.0
                
            crop = img[y1:y2, x1:x2]
            
            # 3. æ°´å¢¨é¢„å¤„ç†
            ink_map = 255.0 - crop.astype(float)
            ink_map[ink_map < 30] = 0 
            
            total_ink = np.sum(ink_map)
            if total_ink < 100: 
                return [0.0, 0.0, 0.0, 0.0], 0.0

            # === A. è®¡ç®— Bias & Rotation ===
            M = cv2.moments(ink_map.astype(np.float32), binaryImage=False)
            
            bias_x, bias_y = 0.0, 0.0
            rotation = 0.0
            
            if M["m00"] != 0:
                cX = M["m10"] / M["m00"]
                cY = M["m01"] / M["m00"]
                h_crop, w_crop = ink_map.shape
                geo_cX = w_crop / 2.0
                geo_cY = h_crop / 2.0
                
                bias_x = (cX - geo_cX) / (geo_cX + 1e-6)
                bias_y = (cY - geo_cY) / (geo_cY + 1e-6)
                bias_x = np.clip(bias_x, -1.0, 1.0)
                bias_y = np.clip(bias_y, -1.0, 1.0)
                
                mu20 = M["mu20"] / M["m00"]
                mu02 = M["mu02"] / M["m00"]
                mu11 = M["mu11"] / M["m00"]
                theta = 0.5 * np.arctan2(2 * mu11, mu20 - mu02)
                rotation = theta / (np.pi / 2)
            
            # === B. è®¡ç®— Flow (æ”¯æŒè´Ÿå€¼æ¯ç¬”) ===
            h_crop, w_crop = ink_map.shape
            avg_density = total_ink / (w_crop * h_crop * 255.0)
            
            sobelx = cv2.Sobel(crop, cv2.CV_64F, 1, 0, ksize=3)
            sobely = cv2.Sobel(crop, cv2.CV_64F, 0, 1, ksize=3)
            grad_mag = np.sqrt(sobelx**2 + sobely**2)
            avg_grad = np.mean(grad_mag) / 255.0 
            
            raw_flow = avg_density / (avg_grad + 0.01)
            
            # [æ ¸å¿ƒæ˜ å°„é€»è¾‘] Pivot = 0.6
            pivot = 0.6
            if raw_flow > pivot:
                flow = (raw_flow - pivot) / (3.0 - pivot + 1e-6)
                flow = np.clip(flow, 0.05, 1.0)
            else:
                flow = (raw_flow - pivot) / pivot
                flow = np.clip(flow, -1.0, -0.05)
            
            return [float(bias_x), float(bias_y), float(rotation), float(flow)], 1.0
            
        except Exception as e:
            return [0.0, 0.0, 0.0, 0.0], 0.0

# === [NEW V9.2] è½¯èƒ½é‡åœºç”Ÿæˆå™¨ï¼šç¡®ä¿è®­ç»ƒä¸æ¨ç†é€»è¾‘å¯¹é½ ===
def generate_soft_energy_field(box_9d, res=64):
    """
    æ ¹æ®æ€åŠ¿å‚æ•°ç”Ÿæˆ 64x64 çš„é«˜æ–¯è½¯èƒ½é‡æ©ç ã€‚
    box_9d: [cls_id, cx, cy, w, h, bx, by, rot, flow]
    """
    _, cx, cy, bw, bh, bx, by, _, _ = box_9d
    
    # 1. è®¡ç®—ä¸æ¨ç†ç«¯ PoemInkAttentionProcessor ç»å¯¹ä¸€è‡´çš„ä¸­å¿ƒ
    # ä½¿ç”¨ 0.15 åç§»ç³»æ•°
    x_c = (cx + bx * 0.15) * res
    y_c = (cy + by * 0.15) * res
    
    # 2. ç”Ÿæˆåæ ‡ç½‘æ ¼
    y_grid, x_grid = np.ogrid[:res, :res]
    dist_sq = (x_grid - x_c)**2 + (y_grid - y_c)**2
    
    # 3. è®¡ç®—è¡°å‡æ ‡å‡†å·® (åŸºäºç‰©ä½“å°ºå¯¸ï¼Œ/4 ç¡®ä¿åœºå¼ºé›†ä¸­)
    sigma = ((bw * res + bh * res) / 4.0) + 1e-6
    
    # 4. ç”Ÿæˆé«˜æ–¯åˆ†å¸ƒ
    field = np.exp(-dist_sq / (2 * sigma**2))
    return field.astype(np.float32)

def parse_args():
    parser = argparse.ArgumentParser(description="Taiyi V9.2: å‡†å¤‡åŒ…å«æ€åŠ¿èƒ½é‡åœºçš„è®­ç»ƒæ•°æ®é›†")
    default_xlsx = "/home/610-sty/layout2paint/dataset/6800poems.xlsx"
    default_img_dir = "/home/610-sty/layout2paint/dataset" 
    default_lbl_dir = "/home/610-sty/layout2paint/dataset/6800/JPEGImages-pre_new_txt"
    
    parser.add_argument("--xlsx_path", type=str, default=default_xlsx)
    parser.add_argument("--images_dir", type=str, default=default_img_dir)
    parser.add_argument("--labels_dir", type=str, default=default_lbl_dir)
    parser.add_argument("--output_dir", type=str, default="./taiyi_energy_dataset_v9_2") 
    parser.add_argument("--resolution", type=int, default=512) 
    return parser.parse_args()

def main():
    args = parse_args()
    os.makedirs(os.path.join(args.output_dir, "images"), exist_ok=True)
    os.makedirs(os.path.join(args.output_dir, "conditioning_images"), exist_ok=True)
    
    # 1. åˆå§‹åŒ–ç»„ä»¶
    ink_generator = InkWashMaskGenerator(width=args.resolution, height=args.resolution)
    gestalt_extractor = FixedVisualGestaltExtractor()
    print("âœ… V9.2 Components (Gestalt Extractor & Ink Generator) initialized.")
    
    # 2. [V9.1 ä¿ç•™é€»è¾‘] å…¨å±€å›¾ç‰‡ç´¢å¼•æ‰«æ
    print(f"ğŸ” æ­£åœ¨æ‰«æå›¾ç‰‡ç›®å½•å»ºç«‹ç´¢å¼•: {args.images_dir} ...")
    image_index = {}
    for root, dirs, files in os.walk(args.images_dir):
        for file in files:
            if file.lower().endswith(('.jpg', '.jpeg', '.png', '.bmp', '.tiff')):
                image_index[file] = os.path.join(root, file)
    print(f"âœ… ç´¢å¼•å»ºç«‹å®Œæˆã€‚å…±æ‰¾åˆ° {len(image_index)} å¼ å›¾ç‰‡ã€‚")

    df = pd.read_excel(args.xlsx_path)
    metadata_entries = []
    success_count = 0

    print(f"ğŸš€ å¼€å§‹å¤„ç†æ•°æ®ï¼Œå…± {len(df)} æ¡...")
    for idx, row in tqdm(df.iterrows(), total=len(df)):
        try:
            raw_img_name = str(row['image']).strip()
            poem = str(row['poem']).strip()
            
            # --- [V9.1 ä¿ç•™é€»è¾‘] æ™ºèƒ½è·¯å¾„æŸ¥æ‰¾ ---
            src_img_path = None
            if os.path.isabs(raw_img_name) and os.path.exists(raw_img_name):
                src_img_path = raw_img_name
            else:
                basename = os.path.basename(raw_img_name)
                src_img_path = image_index.get(basename)
            
            if src_img_path is None: continue

            img_stem = Path(src_img_path).stem
            label_path = os.path.join(args.labels_dir, f"{img_stem}.txt")
            if not os.path.exists(label_path): continue

            # 3. è¯»å– Box å¹¶æå–çœŸå®æ€åŠ¿
            boxes_9d = [] 
            energy_masks_info = [] # [V9.2] å­˜å‚¨è½¯èƒ½é‡æ©ç æ•°æ®
            
            with open(label_path, 'r') as f:
                for line in f:
                    parts = line.strip().split()
                    if len(parts) >= 5: 
                        cls_id, cx, cy, w, h = map(float, parts[:5])
                        
                        # æå– Flow (åŒ…å«è´Ÿå€¼)
                        g_params, valid = gestalt_extractor.extract(src_img_path, [cx, cy, w, h])
                        
                        # å¤±è´¥å¤„ç†
                        if valid < 0.5:
                            g_params = [0.0, 0.0, 0.0, 0.5] 
                            
                        full_box = [cls_id, cx, cy, w, h] + g_params
                        boxes_9d.append(full_box)
                        
                        # [V9.2 æ ¸å¿ƒ] ç”Ÿæˆ 64x64 çš„é«˜æ–¯è½¯èƒ½é‡åœº
                        # å¯¹åº”è®­ç»ƒç«¯ cross-attention çš„ç©ºé—´åˆ†è¾¨ç‡
                        soft_mask = generate_soft_energy_field(full_box, res=64)
                        energy_masks_info.append({
                            "class_id": int(cls_id),
                            "mask_data": soft_mask.tolist() # ä¿å­˜ä¸º list ä»¥åºåˆ—åŒ–åˆ° JSON
                        })
            
            if not boxes_9d: continue

            # 4. ç”Ÿæˆæ¸²æŸ“ Mask (ç”¨äº ControlNet)
            cond_img = ink_generator.convert_boxes_to_mask(boxes_9d) 
            cond_img_name = f"{img_stem}_ink_v9.png"
            cond_img.save(os.path.join(args.output_dir, "conditioning_images", cond_img_name))
            
            # 5. å¤„ç†åŸå›¾ (æ”¯æŒä¸­æ–‡è·¯å¾„åŠ è½½)
            img_array = np.fromfile(src_img_path, dtype=np.uint8)
            img_cv = cv2.imdecode(img_array, cv2.IMREAD_COLOR)
            if img_cv is None: continue
            img_rgb = cv2.cvtColor(img_cv, cv2.COLOR_BGR2RGB)
            target_img = Image.fromarray(img_rgb).resize((args.resolution, args.resolution), Image.BICUBIC)
            
            target_img_name = f"{img_stem}.jpg"
            target_img.save(os.path.join(args.output_dir, "images", target_img_name))

            # 6. [V9.2 å‡çº§] æ„é€ å…ƒæ•°æ®ï¼ŒåŒ…å« layout_energy å­—æ®µ
            metadata_entries.append({
                "image": f"images/{target_img_name}",
                "conditioning_image": f"conditioning_images/{cond_img_name}",
                "text": poem,
                "layout_energy": energy_masks_info # <--- è®­ç»ƒè„šæœ¬ train_taiyi.py å¿…éœ€å­—æ®µ
            })
            
            success_count += 1
            
        except Exception as e:
            continue

    # ä¿å­˜ JSONL
    output_jsonl = os.path.join(args.output_dir, "train.jsonl")
    with open(output_jsonl, 'w', encoding='utf-8') as f:
        for entry in metadata_entries:
            json.dump(entry, f, ensure_ascii=False)
            f.write('\n')
            
    print(f"âœ¨ V9.2 èƒ½é‡åœºæ•°æ®é›†å‡†å¤‡å®Œæˆï¼æˆåŠŸå¤„ç†: {success_count} å¼ ")
    print(f"ğŸ“‚ è¾“å‡ºç›®å½•: {args.output_dir}")

if __name__ == "__main__":
    main()